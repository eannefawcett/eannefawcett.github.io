---
layout: post
title:  "Machine Learning Demystified"
date:   2020-11-11 14:27:43
categories: technical, data science
paginator: Machine Learning Demystified
---

There's a lot of terminology out there being thrown around surrounding machine learning, deep learning, and artificial intelligence. They are different things and mean different things. I would like to share today what my experience with deep learning and discuss some of its applications.

# Deep Learning

Deep learning, while similar to basic the machine learning discussed in my blog post [here][link1], uses a specialized type of algorithm called a neural network. Neural networks have a specific structure to the them, a type of anatomy, that includes an input layer, hidden layers, and an output layer. All layers are organized with something called a node and transitions between node to node from layer to layer are called edges. There are a few different types of neural networks determined by the data type of the input layer. They include standard, convolutional for image or video data, recurrent for audio, text, or times series data, and generative adversarial for gaming. This post will focus on the structure of a neural network.

## Input Layer

This will look different for each type of neural network. This is the first layer of every neural network and can be considered "raw" or processed for analysis data.

For a standard neural network, data can be prepped as it would for any other type of classification or regression machine learning framework. Both supervised and unsupervised learning can be used with a standard neural network.

For the convolutional neural network (CNN), some consideration for how image data is stored needs to be taken into account. Image or video information is stored in the RGB (or red, green, blue) values for each pixel. To create a single input for each image use a process called "unrowing". This process takes all of the pixel data for the RGB values and puts it into something called a "feature vector". What results is basically a long list of the pixel data stored, first the red values, then the green values, then the blue values, where each row is a different input vector. This creates the training data. The training labels list can be generated as a list that has the same number of rows as the training data and is itself a separate "feature vector", with a single number or identifier for the label. The training data and training labels are used together as a single input feature into the neural network. Each piece of pixel information will have the label attached to it. One thing that really defines a CNN is that shape is really important. You can have as many inputs of a fixed size as you want, but they will always reduce down to a fixed size output. Both supervised and unsupervised learning can be used with a CNN.

For the recurrent neural network (RNN), the shape of the input and output can vary as much as the user needs them too to preform the analysis. Part of this is due to the flexibility needed for the "recurrent" part to work, which will be discussed in the hidden layer section. This flexibility allows for the analysis of audio, text, or time series data which often have varying input vector shapes. In other words, not every song has the same number of notes, not every sentence has the same number of words, and time series data often has missing values or collection of the data is sporadic. The flexibility required by the RNN allows room for addressing these issues. A deeper explanation of RNNs can be found [here][link2]. Both supervised and unsupervised learning can be used with an RNN.

For the generative adversarial network (GAN), the input is less important than the structure of the training process. A GAN can be used on a standard neural network, a CNN, or a RNN. What is unique about the GAN is that new inputs are generated by the model and these new inputs are tested against a separate model to determine their validity. Once the second model reaches 50% fake and 50% genuine data, the original model is thought to be capable of producing valid "fakes". This particular method utilizes two different neural networks that communicate as a part of the training process. Find more details [here][link3]. Both supervised and unsupervised learning can be used for the first model, but an unsupervised approach must be used for the second model that is determining the "real" inputs from the "fake" ones.

## Nodes


## Edges


## Hidden Layers


## Output Layer

# A Note on Computer Vision

# Concluding Thoughts



[link1]: https://eannefawcett.github.io/2020/10/26/Machine-Learning-Demystified/
[link2]: https://towardsdatascience.com/recurrent-neural-networks-d4642c9bc7ce
[link3]: https://machinelearningmastery.com/what-are-generative-adversarial-networks-gans/
